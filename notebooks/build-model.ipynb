{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "Data download from Kaggle : https://www.kaggle.com/datasets/rajnathpatel/multilingual-spam-data?resource=download\n",
    "\n",
    "⚠️ Note :  \n",
    "\n",
    "The french mails of this dataset were obtened with automatic translation.  \n",
    "We use this datatset because we didn't find similar data in native French.  \n",
    "However the quality is sufficient for this project not intended for production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_path = \"../data/data-en-hi-de-fr.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)[['text_fr', 'labels']]\n",
    "df = df.rename(columns={\"text_fr\": \"text\", \"labels\": \"label\"})\n",
    "df = df.drop_duplicates(subset=[\"text\"])\n",
    "df = df.replace({\"label\": {\"spam\": 1, \"ham\": 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5134, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>Vous êtes contacté par notre service Rencontre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061</th>\n",
       "      <td>Ces semaines, les offres de membres SavaMob so...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4436</th>\n",
       "      <td>Ne pas b floppy... b snappy &amp; happy! Seul le s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>notre numéro mobile a gagné £5000, pour réclam...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>LookAtMe!: Merci pour votre achat d'un clip vi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>U ont un admirateur secret. REVEAL qui pense U...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Le solde de trésorerie de l'Ur est actuellemen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>Vous avez 1 nouveau message. S'il vous plaît a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4968</th>\n",
       "      <td>Vous pouvez faire un don de 2,50 £ au Fonds as...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3885</th>\n",
       "      <td>Un lien vers votre photo a été envoyé. Vous po...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "4068  Vous êtes contacté par notre service Rencontre...      1\n",
       "4061  Ces semaines, les offres de membres SavaMob so...      1\n",
       "4436  Ne pas b floppy... b snappy & happy! Seul le s...      1\n",
       "579   notre numéro mobile a gagné £5000, pour réclam...      1\n",
       "3132  LookAtMe!: Merci pour votre achat d'un clip vi...      1\n",
       "831   U ont un admirateur secret. REVEAL qui pense U...      1\n",
       "358   Le solde de trésorerie de l'Ur est actuellemen...      1\n",
       "2941  Vous avez 1 nouveau message. S'il vous plaît a...      1\n",
       "4968  Vous pouvez faire un don de 2,50 £ au Fonds as...      1\n",
       "3885  Un lien vers votre photo a été envoyé. Vous po...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df[df.label == 1].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3593,)\n",
      "(1541,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.text.values,\n",
    "    df.label.values,\n",
    "    test_size=0.3,\n",
    "    random_state=123,\n",
    "    stratify=df.label.values\n",
    ")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config :\n",
      "Pipeline(steps=[('vect',\n",
      "                 FeatureUnion(transformer_list=[('vect_1',\n",
      "                                                 TfidfVectorizer(ngram_range=(1,\n",
      "                                                                              3),\n",
      "                                                                 token_pattern='(?u)\\\\b\\\\w+\\\\b')),\n",
      "                                                ('vect_2',\n",
      "                                                 TfidfVectorizer(analyzer='char_wb',\n",
      "                                                                 ngram_range=(2,\n",
      "                                                                              3)))])),\n",
      "                ('clf',\n",
      "                 CalibratedClassifierCV(base_estimator=SGDClassifier()))])\n",
      "\n",
      "Scores :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1349\n",
      "           1       0.98      0.91      0.94       192\n",
      "\n",
      "    accuracy                           0.99      1541\n",
      "   macro avg       0.98      0.95      0.97      1541\n",
      "weighted avg       0.99      0.99      0.99      1541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = Pipeline([\n",
    "    ('vect',\n",
    "         FeatureUnion([\n",
    "             ('vect_1', TfidfVectorizer(\n",
    "                analyzer='word',\n",
    "                token_pattern=r'(?u)\\b\\w+\\b',\n",
    "                lowercase=True,\n",
    "                ngram_range=(1, 3))),\n",
    "             ('vect_2', TfidfVectorizer(\n",
    "                analyzer='char_wb',\n",
    "                lowercase=True,\n",
    "                ngram_range=(2, 3))),\n",
    "         ]),\n",
    "    ),  \n",
    "    ('clf',\n",
    "        CalibratedClassifierCV(\n",
    "            SGDClassifier(loss=\"hinge\"),\n",
    "            # LinearSVC(),\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "params = {\n",
    "    'clf__method': [\"sigmoid\", \"isotonic\"],\n",
    "    'clf__base_estimator__class_weight': [None, \"balanced\"],\n",
    "    'clf__base_estimator__penalty': [\"l2\", \"l1\", \"elasticnet\"]\n",
    "    }\n",
    "\n",
    "gs = GridSearchCV(model, params, scoring=\"f1_macro\")\n",
    "model = gs.fit(X_train, y_train).best_estimator_\n",
    "\n",
    "\n",
    "print(\"Best config :\")\n",
    "print(model)\n",
    "\n",
    "print()\n",
    "print(\"Scores :\")\n",
    "y_pred = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "confidence: 79.3 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "features_names = model.named_steps[\"vect\"].get_feature_names_out()\n",
    "\n",
    "def get_scores(feats, features_names, n_feats=10):\n",
    "    idx = np.nonzero(feats)[1]\n",
    "    names = features_names[idx]\n",
    "    coefs = feats.toarray()[0][idx]\n",
    "    scores = {name: round(coef, 3) for name, coef in zip(names, coefs)}\n",
    "    scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:n_feats]\n",
    "    return scores\n",
    "\n",
    "text = \"\"\"\n",
    "Bonjour à toutes et à tous,\n",
    "\n",
    "Étant désormais officiellement positive au covid, la séance de cette\n",
    "semaine se déroulera malheureusement une nouvelle fois en visio. Les\n",
    "informations de connexion seront mises en ligne sur la page iCampus du\n",
    "cours juste avant le cours.\n",
    "\n",
    "Bien cordialement\n",
    "\"\"\"\n",
    "\n",
    "feats = model.named_steps[\"vect\"].transform([text])\n",
    "proba = model.named_steps[\"clf\"].predict_proba(feats)[0]\n",
    "pred = 1 if proba[1] > proba[0] else 0\n",
    "score = round(proba[pred] * 100, 1)\n",
    "\n",
    "print(\"SPAM !!!!\" if pred else \"OK\")\n",
    "print(f\"confidence: {score} %\")\n",
    "\n",
    "if pred:\n",
    "    print()\n",
    "    scores = get_scores(feats, features_names, n_feats=20)\n",
    "    for name, coef in scores:\n",
    "        print(f\"{name}\\t\\t{coef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "model_to_save = model.fit(df.text.values, df.label.values)\n",
    "\n",
    "def save(\n",
    "    model, prefix=\"\", directory='../app/ml_models'\n",
    "):\n",
    "    current_time = strftime(\"%Y%m%d-%H%M%S\", gmtime())\n",
    "    dir_name = f\"{prefix}-{current_time}\"\n",
    "    dir_path = os.path.join(directory, dir_name)\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    joblib.dump(model, os.path.join(dir_path, \"model.joblib\"))\n",
    "\n",
    "save(model_to_save, prefix=\"anti-spam\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ml-anti-spam-fr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc6d1c5837146cd92587e058b2b37630b994b8187f925cab1be05fb8d4951966"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
